---
title: "hw_3_Zelenkova"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1.1
```{r}
library(tidyverse)
library(bootstrap)
library(mosaic)
library(irr)
library(tibble)
library(dplyr)

df = read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/Lera-Z/hw3_binomial_ci/hw3_wodehouse.csv')
df %>% 
  subset(word == 'сэр') %>% 
  count(chapter) ->
  chapter_sir
n_words = as.vector(table(df$chapter))

chapter_sir['n_words'] <- n_words

chapter_sir['averages'] <- chapter_sir$n/chapter_sir$n_words

grand_mean <- mean(chapter_sir$n/chapter_sir$n_words)

as_tibble(grand_mean)
```

### 1.2
```{r}
set.seed(42)
 
chapter_bs <- bootstrap(chapter_sir$averages, nboot = 10000, theta = mean)$thetastar
chapter_bs <- data_frame(means = chapter_bs) 

chapter_bs %>%
  summarise(mean = mean(means),
            q1 = quantile(means, 0.025),
            q2 = quantile(means, 0.975))->
  chapter_stats
as_tibble(chapter_stats[,-1])

```

### 1.3
```{r}
chapter_sir %>%
  group_by(chapter) %>%
  mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
         up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2]) ->
  chapter_sir

chapter_sir %>%
  mutate(length = up_ci - low_ci) ->
  chapter_sir
as_tibble(chapter_sir[which.max(chapter_sir$length),-7])

```

### 1.4
```{r}
mu <- mean(chapter_sir$averages)
var <- var(chapter_sir$averages)
alpha0 <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta0 <- alpha0 * (1 / mu - 1)


chapter_sir %>%
  group_by(chapter) %>% 
  mutate(alpha_post = n + alpha0,
         beta_post = n_words-n+beta0,
         average_post = alpha_post/(alpha_post+beta_post),
         cred_int_l = qbeta(.025, alpha_post, beta_post),
         cred_int_h = qbeta(.975, alpha_post, beta_post)) ->
  posterior


as_tibble(posterior[which.max(posterior$length),-8])
```

### 1.5
```{r}
as_tibble(chapter_sir[which.min(chapter_sir$length),-7])
```

### 1.6
```{r}

as_tibble(posterior[which.min(posterior$length),-8])
```

### 1.7
```
Напишите короткий текст, комментирующий наблюдаемые сходства/различия между оценками среднего и доверительных интервалов количества употреблений слова “сэр” во всех главах романа. Что можно сказать про разные главы? Что можно сказать о сходстве/различиях фриквентистсткой и байесовской оценок наблюдаемых параметров?
  
Биномиальный доверительный интервал, байесовский биномиальный доверительный интервал и интервал бутстрепа дают очень близкие результаты. И у того, и у другого способа подсчета интервала минимальное значение пришлось на главу 3, а максимальное - на главу 12.

Встречаемость слова "сэр" варьируется от главы к главе, меньше всего слова "сэр" в 3 главе (8 вхождений), а больше всего - в 14 главе (77 вхождений). 

В бутстрапе среднее: 0.007290931, а grand mean - 0.007297607 (очень близкие значения).
```