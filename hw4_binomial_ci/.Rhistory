df = data_frame(aver = averages_sir, chapter=unique(data$chapter), n_words = table(data$chapter))
library(tidyverse)
library(bootstrap)
library(mosaic)
library(irr)
library(tibble)
library(dplyr)
data = read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/Lera-Z/hw3_binomial_ci/hw3_wodehouse.csv')
data = as_tibble(data)
newdata <- subset(data, word == 'сэр')
averages_sir = as.vector(table(newdata$chapter))/as.vector(table(data$chapter))
df = data_frame(aver = averages_sir, chapter=unique(data$chapter), n_words = table(data$chapter))
View(df)
tibble(mean(averages_sir))
bs <- bootstrap(averages_sir, nboot = 10000, theta = mean)$thetastar
bs <- data_frame(means = bs)
bs %>%
summarise(mean = mean(means),
q1 = quantile(means, 0.025),
q2 = quantile(means, 0.975))->
bs_stats
bs_stats
bs %>%
ggplot(aes(means)) +
geom_histogram(fill = "lightblue")+
theme_bw()+
labs(title = 'Средняя доля слова "сэр" на основе глав из романа П. Г. Вудхауза “Фамильная честь Вустеров”', subtitle = "Среднее и 95% бутстрэпнутый доверительный интервал на основе 10000 бутстрэп-подвыборок")+
geom_vline(xintercept = unlist(bs_stats), lty = c(2, 3, 3))
df %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = df$averages_sir, n = df$n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = df$averages_sir, n = df$n_words, ci.method = "Clopper-Pearson")$conf.int[2]) ->     final_res
View(df)
df %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = df$aver, n = df$n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = df$aver, n = df$n_words, ci.method = "Clopper-Pearson")$conf.int[2]) ->     final_res
View(final_res)
count_sir = as.vector(table(newdata$chapter))
averages_sir = as.vector(table(newdata$chapter))/as.vector(table(data$chapter))
df = data_frame(aver = count_sir, chapter=unique(data$chapter), n_words = table(data$chapter))
View(df)
df %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = df$aver, n = df$n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = df$aver, n = df$n_words, ci.method = "Clopper-Pearson")$conf.int[2]) ->     final_res
View(final_res)
View(df)
head(df)
group_by(df$chapter)
y = group_by(df$chapter)
y = group_by(df$chapter)
y = group_by(df, chapter)
group_by(df, chapter)
group_by(df, chapter)
y = group_by(df, chapter)$aver
y = group_by(df, chapter)$n_words
typeof(y)
y = list(group_by(df, chapter)$n_words)
typeof(y)
View(y)
View(df)
y = group_by(df, chapter)$n_words
y = as.vector(group_by(df, chapter)$n_words)
df %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = df$aver, n = y, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = df$aver, n = df$n_words, ci.method = "Clopper-Pearson")$conf.int[2])
df %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = aver, n = y, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = df$aver, n = df$n_words, ci.method = "Clopper-Pearson")$conf.int[2])
df %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = averages_sir, n = y, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = averages_sir, n = y, ci.method = "Clopper-Pearson")$conf.int[2])
typeof(y)
df = read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/Lera-Z/hw3_binomial_ci/hw3_wodehouse.csv')
df %>%
filter(word == "сэр") %>%
count(chapter) ->
chapter_av
df %>%
group_by(chapter) %>%
count(chapter) ->
total
chapter_av['total'] <- total$n
chapter_av %>%
mutate(average = n/total) %>%
arrange(desc(average)) %>%
summarise(g_mean = mean(average)) ->
grand_mean
as_tibble(grand_mean)
set.seed(42)
chapter_av %>%
mutate(average = n/total) %>%
arrange(desc(average)) ->
chapter_av
chapter_bs <- bootstrap(chapter_av$average, nboot = 10000, theta = mean)$thetastar
chapter_bs <- data_frame(means = chapter_bs)
chapter_bs %>%
summarise(mean = mean(means),
q1 = quantile(means, 0.025),
q2 = quantile(means, 0.975))->
chapter_stats
as_tibble(chapter_stats[,-1])
chapter_av %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = total, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = total, ci.method = "Clopper-Pearson")$conf.int[2]) ->
chapter_av
chapter_av %>%
ggplot(aes(chapter, average))+
geom_point()+
geom_pointrange(aes(ymin = low_ci, ymax = up_ci))+
theme_bw()+
coord_flip()+
labs(title = 'Среднее и 95% CI употребления "не" в рассказах А. Чехова',
x = "", y = "")
chapter_av %>%
arrange(total) %>%
mutate (length = up_ci - low_ci) ->
chapter_av
as_tibble(chapter_av[which.max(chapter_av$length),-7])
chapter_av %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = total, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = total, ci.method = "Clopper-Pearson")$conf.int[2]) ->
chapter_av
chapter_av %>%
arrange(total) %>%
mutate (length = up_ci - low_ci) ->
chapter_av
as_tibble(chapter_av[which.max(chapter_av$length),-7])
chapter_av %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = total, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = total, ci.method = "Clopper-Pearson")$conf.int[2]) ->
chapter_see
chapter_av %>%
arrange(total) %>%
mutate (length = up_ci - low_ci) ->
chapter_av
as_tibble(chapter_av[which.max(chapter_av$length),-7])
View(chapter_see)
View(chapter_av)
df = read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/Lera-Z/hw3_binomial_ci/hw3_wodehouse.csv')
df %>%
filter(word == "сэр") %>%
count(chapter) ->
chapter_av
View(chapter_av)
df %>%
subset(data, word == 'сэр') ->
chapter_sir
df %>%
subset(df, word == 'сэр') ->
chapter_sir
View(df)
df %>%
subset(word == 'сэр') ->
chapter_sir
View(chapter_sir)
df %>%
subset(word == 'сэр') ->
count(chapter)
View(df)
df %>%
subset(word == 'сэр') %>%
count(chapter) ->
chapter_sir
df %>%
as.vector(table(chapter)) ->
total
View(df)
df %>%
as.vector(table(df$chapter)) ->
total
df %>%
table(chapter) ->
n_words
df %>%
table(df$chapter) ->
n_words
View(df)
table(df$chapter)
as.vector(table(df$chapter))
length(as.vector(table(df$chapter)))
n_words = as.vector(table(df$chapter))
chapter_sir['n_words'] <- n_words
View(chapter_sir)
chapter_average %>%
mutate(average = n/n_words) %>%
arrange(desc(average)) %>%
summarise(g_mean = mean(average)) ->
grand_mean
chapter_sir %>%
mutate(average = n/n_words) %>%
arrange(desc(average)) %>%
summarise(g_mean = mean(average)) ->
grand_mean
View(grand_mean)
View(chapter_sir)
grand_mean <- mean(chapter_sir$n/chapter_sir$n_words)
as_tibble(grand_mean)
View(chapter_sir)
View(chapter_av)
chapter_sir['averages'] <- chapter_sir$n/chapter_sir$n_words
set.seed(42)
chapter_bs <- bootstrap(chapter_sir$averages, nboot = 10000, theta = mean)$thetastar
chapter_bs <- data_frame(means = chapter_bs)
chapter_bs %>%
summarise(mean = mean(means),
q1 = quantile(means, 0.025),
q2 = quantile(means, 0.975))->
chapter_stats
as_tibble(chapter_stats[,-1])
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2]) ->
chapter_sir
chapter_av %>%
arrange(total) %>%
mutate (length = up_ci - low_ci) ->
chapter_av
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2]) ->
chapter_sir
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2])
chapter_sir %>%
arrange(total) %>%
mutate (length = up_ci - low_ci) ->
chapter_av
as_tibble(chapter_av[which.max(chapter_av$length),-7])
View(chapter_sir)
chapter_sir %>%
mutate(length = up_ci - low_ci) ->
chapter_sir
as_tibble(chapter_av[which.max(chapter_av$length),-7])
---
title: "hw_3_Zelenkova"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### 1.1
```{r}
library(tidyverse)
library(bootstrap)
library(mosaic)
library(irr)
library(tibble)
library(dplyr)
df = read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/Lera-Z/hw3_binomial_ci/hw3_wodehouse.csv')
df %>%
subset(word == 'сэр') %>%
count(chapter) ->
chapter_sir
n_words = as.vector(table(df$chapter))
chapter_sir['n_words'] <- n_words
chapter_sir['averages'] <- chapter_sir$n/chapter_sir$n_words
grand_mean <- mean(chapter_sir$n/chapter_sir$n_words)
as_tibble(grand_mean)
```
### 1.2
```{r}
set.seed(42)
chapter_bs <- bootstrap(chapter_sir$averages, nboot = 10000, theta = mean)$thetastar
chapter_bs <- data_frame(means = chapter_bs)
chapter_bs %>%
summarise(mean = mean(means),
q1 = quantile(means, 0.025),
q2 = quantile(means, 0.975))->
chapter_stats
as_tibble(chapter_stats[,-1])
```
### 1.3
```{r}
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2])
chapter_sir %>%
mutate(length = up_ci - low_ci) ->
chapter_sir
as_tibble(chapter_av[which.max(chapter_av$length),-7])
```
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2])
chapter_sir %>%
mutate(length = up_ci - low_ci) ->
chapter_sir
---
title: "hw_3_Zelenkova"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### 1.1
```{r}
library(tidyverse)
library(bootstrap)
library(mosaic)
library(irr)
library(tibble)
library(dplyr)
df = read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/Lera-Z/hw3_binomial_ci/hw3_wodehouse.csv')
df %>%
subset(word == 'сэр') %>%
count(chapter) ->
chapter_sir
n_words = as.vector(table(df$chapter))
chapter_sir['n_words'] <- n_words
chapter_sir['averages'] <- chapter_sir$n/chapter_sir$n_words
grand_mean <- mean(chapter_sir$n/chapter_sir$n_words)
as_tibble(grand_mean)
```
### 1.2
```{r}
set.seed(42)
chapter_bs <- bootstrap(chapter_sir$averages, nboot = 10000, theta = mean)$thetastar
chapter_bs <- data_frame(means = chapter_bs)
chapter_bs %>%
summarise(mean = mean(means),
q1 = quantile(means, 0.025),
q2 = quantile(means, 0.975))->
chapter_stats
as_tibble(chapter_stats[,-1])
```
### 1.3
```{r}
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2])
chapter_sir %>%
mutate(length = up_ci - low_ci) ->
chapter_sir
as_tibble(chapter_sir[which.max(chapter_av$length),-7])
```
library(tidyverse)
library(bootstrap)
library(mosaic)
library(irr)
library(tibble)
library(dplyr)
df = read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/Lera-Z/hw3_binomial_ci/hw3_wodehouse.csv')
df %>%
subset(word == 'сэр') %>%
count(chapter) ->
chapter_sir
n_words = as.vector(table(df$chapter))
chapter_sir['n_words'] <- n_words
chapter_sir['averages'] <- chapter_sir$n/chapter_sir$n_words
grand_mean <- mean(chapter_sir$n/chapter_sir$n_words)
as_tibble(grand_mean)
set.seed(42)
chapter_bs <- bootstrap(chapter_sir$averages, nboot = 10000, theta = mean)$thetastar
chapter_bs <- data_frame(means = chapter_bs)
chapter_bs %>%
summarise(mean = mean(means),
q1 = quantile(means, 0.025),
q2 = quantile(means, 0.975))->
chapter_stats
as_tibble(chapter_stats[,-1])
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2])
chapter_sir %>%
mutate(length = up_ci - low_ci) ->
chapter_sir
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2])
chapter_sir %>%
mutate(length = up_ci - low_ci) ->
chapter_sir
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2]) ->
chapter_sir
chapter_sir %>%
mutate(length = up_ci - low_ci) ->
chapter_sir
as_tibble(chapter_sir[which.max(chapter_av$length),-7])
chapter_sir %>%
mutate(length = up_ci - low_ci) ->
chapter_sir
as_tibble(chapter_sir[which.max(chapter_sir$length),-7])
View(df)
mu <- mean(chapter_sir$averages)
var <- var(chapter_sir$averages)
alpha0 <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta0 <- alpha0 * (1 / mu - 1)
df %>%
group_by(chapter) %>%
mutate(alpha_post = n+alpha0,
beta_post = n_words-n+beta0,
average_post = alpha_post/(alpha_post+beta_post),
cred_int_l = qbeta(.025, alpha_post, beta_post),
cred_int_h = qbeta(.975, alpha_post, beta_post)) ->
posterior
chapter_sir %>%
group_by(chapter) %>%
mutate(alpha_post = n + alpha0,
beta_post = n_words-n+beta0,
average_post = alpha_post/(alpha_post+beta_post),
cred_int_l = qbeta(.025, alpha_post, beta_post),
cred_int_h = qbeta(.975, alpha_post, beta_post)) ->
posterior
posterior %>%
select(chapter, n_words, averages, average_post) %>%
arrange(n_words)
as_tibble(chapter_sir[which.max(chapter_sir$length),-7])
as_tibble(posterior[which.max(posterior$length),-7])
as_tibble(posterior[which.max(posterior$length),-5])
as_tibble(posterior[which.max(posterior$length),-10])
as_tibble(posterior[which.max(posterior$length),-1])
as_tibble(posterior[which.max(posterior$length)])
as_tibble(posterior[which.max(posterior$length),-1])
as_tibble(posterior[which.max(posterior$length),-5])
as_tibble(posterior[which.max(posterior$length),-15])
as_tibble(posterior[which.max(posterior$length),-11])
as_tibble(posterior[which.max(posterior$length),5])
as_tibble(posterior[which.max(posterior$length),2])
as_tibble(posterior[which.max(posterior$length),-10])
as_tibble(posterior[which.max(posterior$length),-9])
as_tibble(posterior[which.max(posterior$length),-8])
View(posterior)
chapter_sir %>%
group_by(chapter) %>%
mutate(alpha_post = n + alpha0,
beta_post = n_words-n+beta0,
average_post = alpha_post/(alpha_post+beta_post),
cred_int_l = qbeta(.025, alpha_post, beta_post),
cred_int_h = qbeta(.975, alpha_post, beta_post)) ->
posterior
as_tibble(posterior[which.max(posterior$length),-8])
as_tibble(chapter_sir[which.min(chapter_sir$length),-7])
as_tibble(posterior[which.min(posterior$length),-8])
View(chapter_stats)
View(chapter_stats)
as_tibble(chapter_sir[which.max(chapter_sir$length),-7])
as_tibble(posterior[which.max(posterior$length),-8])
as_tibble(chapter_sir[which.min(chapter_sir$length),-7])
as_tibble(posterior[which.min(posterior$length),-8])
View(chapter_sir)
View(chapter_sir)
View(chapter_stats)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(bootstrap)
library(mosaic)
library(irr)
library(tibble)
library(dplyr)
df = read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/Lera-Z/hw3_binomial_ci/hw3_wodehouse.csv')
df %>%
subset(word == 'сэр') %>%
count(chapter) ->
chapter_sir
n_words = as.vector(table(df$chapter))
chapter_sir['n_words'] <- n_words
chapter_sir['averages'] <- chapter_sir$n/chapter_sir$n_words
grand_mean <- mean(chapter_sir$n/chapter_sir$n_words)
as_tibble(grand_mean)
set.seed(42)
chapter_bs <- bootstrap(chapter_sir$averages, nboot = 10000, theta = mean)$thetastar
chapter_bs <- data_frame(means = chapter_bs)
chapter_bs %>%
summarise(mean = mean(means),
q1 = quantile(means, 0.025),
q2 = quantile(means, 0.975))->
chapter_stats
as_tibble(chapter_stats[,-1])
chapter_sir %>%
group_by(chapter) %>%
mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2]) ->
chapter_sir
chapter_sir %>%
mutate(length = up_ci - low_ci) ->
chapter_sir
as_tibble(chapter_sir[which.max(chapter_sir$length),-7])
mu <- mean(chapter_sir$averages)
var <- var(chapter_sir$averages)
alpha0 <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta0 <- alpha0 * (1 / mu - 1)
chapter_sir %>%
group_by(chapter) %>%
mutate(alpha_post = n + alpha0,
beta_post = n_words-n+beta0,
average_post = alpha_post/(alpha_post+beta_post),
cred_int_l = qbeta(.025, alpha_post, beta_post),
cred_int_h = qbeta(.975, alpha_post, beta_post)) ->
posterior
as_tibble(posterior[which.max(posterior$length),-8])
as_tibble(chapter_sir[which.min(chapter_sir$length),-7])
as_tibble(posterior[which.min(posterior$length),-8])
